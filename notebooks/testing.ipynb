{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f77703d",
   "metadata": {},
   "source": [
    "This notebook is used for evaluating the trained models on different splis and visualizing the batch effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f59aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.split(os.getcwd())[0]\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from training.model import ResNet\n",
    "from training.data import JUMPCPDataset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c470ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path = \"/system/user/studentwork/seibezed/bachelor/logs/imgres=499_lr=0.001_wd=0.1_agg=True_model=ResNet50_world_size=4batchsize=32_workers=8_date=2025-10-27-19-55-19__fold4/checkpoints/epoch_42.pt\"\n",
    "cross_validation = True\n",
    "folds = 5\n",
    "epochs = [42, 41, 42, 40, 42]\n",
    "checkpoint_path = [f\"/system/user/studentwork/seibezed/bachelor/logs/imgres=499_lr=0.001_wd=0.1_agg=True_model=ResNet50_world_size=4batchsize=32_workers=8_date=2025-10-27-19-55-19__fold{fold}/checkpoints/epoch_{epoch}.pt\" for fold, epoch in zip(range(folds),epochs)]\n",
    "model = \"ResNet50\"\n",
    "test_file = \"/system/user/studentwork/seibezed/bachelor/data/random_seed1234_test.csv\"\n",
    "mapping = \"/system/user/studentwork/seibezed/bachelor/data/class_mapping_seed1234.json\"\n",
    "image_path = \"/system/user/publicdata/jumpcp/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a783853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_models_to_fp32(model):\n",
    "    for p in model.parameters():\n",
    "        p.data = p.data.float()\n",
    "        if p.grad:\n",
    "            p.grad.data = p.grad.data.float()\n",
    "\n",
    "def load_model(checkpoint_path, device, model):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    state_dict = checkpoint[\"state_dict\"]\n",
    "\n",
    "    model_config_file = os.path.join(src_path, f\"training/model_parameter/{model.replace('/', '-')}.json\")\n",
    "    assert os.path.exists(model_config_file)\n",
    "    with open(model_config_file, 'r') as f:\n",
    "        model_info = json.load(f)\n",
    "    model = ResNet(**model_info)\n",
    "\n",
    "    if str(device) == \"cpu\":\n",
    "        model.float()\n",
    "    print(device)\n",
    "\n",
    "    new_state_dict = {k[len('module.'):]: v for k,v in state_dict.items()}\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f76a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(test_file, model_path, model, img_path, mapping_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(torch.cuda.device_count())\n",
    "\n",
    "    model = load_model(model_path, device, model)\n",
    "\n",
    "    test_data = JUMPCPDataset(test_file, img_path, mapping_path)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_metadata = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(DataLoader(test_data, num_workers=20, batch_size=64)):\n",
    "            imgs, labels,_, metadata = batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(imgs)\n",
    "\n",
    "            all_predictions.append(predictions)\n",
    "            all_labels.append(labels)\n",
    "            all_metadata.append(metadata)\n",
    "\n",
    "    #flat_metadata = [item for batch in all_metadata for item in batch]\n",
    "    flat_metadata = []\n",
    "    for batch_meta in all_metadata:  # each is a dict of lists\n",
    "        (batch_key, batch_items), (source_key, source_items) = batch_meta.items()\n",
    "        for i in range(len(batch_items)):\n",
    "            flat_metadata.append({batch_key: batch_items[i], source_key: source_items[i]})\n",
    "\n",
    "    return torch.cat(all_predictions), torch.cat(all_labels), pd.DataFrame(flat_metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b0614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/155 [00:00<?, ?it/s]/system/apps/studentenv/seibezed/jumpcp-py310/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "100%|██████████| 155/155 [01:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:17<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:15<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:13<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [01:13<00:00,  2.10it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "if cross_validation:\n",
    "    for cpath in checkpoint_path:\n",
    "        pred, labels, metadata = main(test_file, cpath, model, image_path, mapping)\n",
    "        data.append([pred, labels, metadata])\n",
    "else:\n",
    "    pred, labels, metadata = main(test_file, checkpoint_path, model, image_path, mapping)\n",
    "    data.append([pred, labels, metadata])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9955cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual acc: [0.969794928780685, 0.9729265582382058, 0.9698959490857663, 0.9682796242044651, 0.9713102333569047]\n",
      "Test set: \n",
      " Mean: 0.9704414587332053\n",
      " Std: 0.001569687814894813\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for pred, labels, metadata in data:\n",
    "    pred_labels = torch.argmax(pred, dim=1)\n",
    "    correct = (pred_labels == labels).sum().item()\n",
    "    acc = correct/len(labels)\n",
    "    accuracies.append(acc)\n",
    "print(f\"Individual acc: {accuracies}\")\n",
    "print(f\"Test set: \\n Mean: {np.mean(accuracies)}\\n Std: {np.std(accuracies)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3cd8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JCP2022_035095: 0.9946117274167987\n",
      "JCP2022_046054: 0.9860728744939271\n",
      "JCP2022_064022: 0.9952960259529604\n",
      "JCP2022_085227: 0.904527402700556\n",
      "JCP2022_012818: 0.991618734593262\n",
      "JCP2022_025848: 0.9466353677621283\n",
      "JCP2022_037716: 0.9869674185463658\n",
      "JCP2022_050797: 0.9600985221674877\n"
     ]
    }
   ],
   "source": [
    "id_mapping = \"/system/user/studentwork/seibezed/bachelor/data/id_mapping_seed1234.json\"\n",
    "\n",
    "#load mapping\n",
    "with open(id_mapping, \"r\") as f:\n",
    "    id_to_class = json.load(f)\n",
    "\n",
    "#compute accuracy per label    \n",
    "label_acc = {}\n",
    "for pred, labels, metadata in data:\n",
    "\n",
    "    for i in labels.unique():\n",
    "        filter_pred = pred[labels==i]\n",
    "        filter_pred = torch.argmax(filter_pred, dim=1)\n",
    "        correct = (filter_pred == i).sum().item()\n",
    "        acc = correct/len(filter_pred)\n",
    "\n",
    "        key = id_to_class[str(i.item())]\n",
    "        if key not in label_acc:\n",
    "            label_acc[key] = []\n",
    "        label_acc[key].append(acc)\n",
    "\n",
    "for key, value in label_acc.items():\n",
    "    print(f\"{key}: {np.mean(value)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dbd9dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP_27_all_Phenix1: 0.9932971014492754\n",
      "CP_32_all_Phenix1: 0.9757307351638618\n",
      "CP_28_all_Phenix1: 0.9829743589743589\n",
      "CP_26_all_Phenix1: 0.9859525899912203\n",
      "CP_31_all_Phenix1: 0.879831223628692\n",
      "CP_25_all_Phenix1: 0.9949647532729105\n",
      "CP60: 0.9934875749785774\n",
      "CP59: 0.9460055096418734\n",
      "CP_29_all_Phenix1: 0.9898032200357783\n"
     ]
    }
   ],
   "source": [
    "id_mapping = \"/system/user/studentwork/seibezed/bachelor/data/id_mapping_seed1234.json\"\n",
    "\n",
    "#compute accuracy per batch\n",
    "batch_acc = {}\n",
    "for pred, labels, metadata in data:\n",
    "    for i in metadata[\"batch\"].unique():\n",
    "        filter_pred = pred[metadata[\"batch\"]==i]\n",
    "        filter_labels = labels[metadata[\"batch\"]==i]\n",
    "        filter_pred = torch.argmax(filter_pred, dim=1)\n",
    "        correct = (filter_pred == filter_labels).sum().item()\n",
    "        acc = correct/len(filter_pred)\n",
    "\n",
    "        key = i\n",
    "        if key not in batch_acc:\n",
    "            batch_acc[key] = []\n",
    "        batch_acc[key].append(acc)\n",
    "\n",
    "for key, value in batch_acc.items():\n",
    "    print(f\"{key}: {np.mean(value)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85894de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: \n",
      " Mean: 0.9381401471043818\n",
      " Std: 0.003966296158951751\n",
      "\n",
      "Test set: \n",
      " Mean: 0.9160319944357503\n",
      " Std: 0.00561251023737622\n"
     ]
    }
   ],
   "source": [
    "#TESTING PURPOSES\n",
    "#seperated\n",
    "#epoch 45,40,45,44,42\n",
    "acc_val = [0.9374835483021848, 0.9352461173993156, 0.9407738878652276, 0.9330086864964464, 0.9441884954587337]\n",
    "acc_test = [0.9160146061554513,0.9104503564597461,0.9260998087289167,0.9110589462702139,0.9165362545644236]\n",
    "\n",
    "print(f\"Validation set: \\n Mean: {np.mean(acc_val)}\\n Std: {np.std(acc_val)}\\n\")\n",
    "print(f\"Test set: \\n Mean: {np.mean(acc_test)}\\n Std: {np.std(acc_test)}\")\n",
    "\n",
    "#random\n",
    "#epoch 42, 41, 42, 40, 42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jumpcp-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
